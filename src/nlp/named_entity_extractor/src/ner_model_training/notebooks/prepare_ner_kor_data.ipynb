{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "future-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "import csv\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "decd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smaller-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirectories(folder_path):\n",
    "    return [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
    "\n",
    "def get_files_in_folder(folder_path):\n",
    "    return [f for f in listdir(folder_path) if isfile(join(folder_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "scientific-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data downloaded from https://github.com/nytud/NYTK-NerKor\n",
    "# https://link.springer.com/chapter/10.1007/978-3-030-83527-9_19\n",
    "\n",
    "base_path = \"/Users/attilanagy/Personal/NYTK-NerKor/data/genres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-triumph",
   "metadata": {},
   "source": [
    "## Load data and convert it to a nicer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "first-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conll_file(path):\n",
    "    # Return two lists:\n",
    "        # - the first is the list of token lists\n",
    "        # - the second is the list of token annotation lists \n",
    "    sentence_list = []\n",
    "    sentence_label_list = []\n",
    "    with open(path) as f:\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            splitted = line.split('\\t')\n",
    "            # This conll format should have 6 columns, \n",
    "            # we check for the newlines here separating the sentences\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "                \n",
    "            elif len(splitted) != 6:\n",
    "                sentence_list.append(tokens)\n",
    "                sentence_label_list.append(labels)\n",
    "                tokens = []\n",
    "                labels = []\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                splitted = line.split('\\t')\n",
    "                token_surface_form = splitted[0]\n",
    "                token_label = splitted[-1]\n",
    "                tokens.append(token_surface_form.strip())\n",
    "                labels.append(token_label.strip())\n",
    "                \n",
    "    return sentence_list, sentence_label_list\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "chubby-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, labels = load_conll_file('/Users/attilanagy/Personal/NYTK-NerKor/data/genres/wikipedia/no-morph/huwiki_200_18.conllup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "manufactured-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Csáktornyától', '12', 'km-re', 'keletre', 'fekszik', '.'] \n",
      " ['B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
      "6 6\n",
      "----------------------------\n",
      "['Az', 'Intermission', 'az', 'amerikai', 'Dio', 'heavy', 'metal', 'zenekar', 'első', 'koncertlemeze', '.'] \n",
      " ['O', 'B-MISC', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "11 11\n",
      "----------------------------\n",
      "['Dio', 'csalódottságában', 'nevezte', 'el', 'az', 'albumot', 'Intermission-nek', '(', 'felvonásköz', ',', 'szünet', ')', '.'] \n",
      " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "13 13\n",
      "----------------------------\n",
      "['1896', 'októberében', 'Egerben', 'járt', ',', 's', 'barátai', 'ösztönzésére', '1897', '.'] \n",
      " ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "10 10\n",
      "----------------------------\n",
      "['A', 'helyszűke', 'hamarosan', 'nyilvánvalónak', 'bizonyult', ',', 'emellett', 'Gárdonyit', 'zavarta', 'munkájában', 'az', 'utcáról', 'beszűrődő', 'zaj', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "15 15\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that reading a file works correctly\n",
    "for i in range(5):\n",
    "    print(f\"{sents[i]} \\n {labels[i]}\")\n",
    "    print(len(sents[i]), len(labels[i]))\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "coastal-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path):\n",
    "    # load data by genre\n",
    "    # Returns:\n",
    "        # Map of genre_name -> dataset, where dataset is:\n",
    "        # tuple with sentence lists and token annotation lists\n",
    "    data = {}\n",
    "    \n",
    "    genre_paths = get_subdirectories(base_path)\n",
    "    for genre_path in genre_paths:\n",
    "        genre_name = genre_path.split('/')[-1]\n",
    "        if genre_name not in data:\n",
    "            sentence_list = []\n",
    "            sentence_label_list = []\n",
    "            data[genre_name] = []\n",
    "            \n",
    "        subdirs = get_subdirectories(genre_path)\n",
    "        # there is both morph and no-morph version of the data\n",
    "        # take no-morph\n",
    "        # the folders are pretty inconsistent\n",
    "        if len(subdirs) == 2:\n",
    "            path = list(filter(lambda x: x.endswith('no-morph'), subdirs))[0]\n",
    "            \n",
    "        # there is only a single subfolder (morph or no-morph)\n",
    "        else:\n",
    "            path = subdirs[0]\n",
    "            \n",
    "        files = get_files_in_folder(path)\n",
    "        file_paths = [os.path.join(path, file) for file in files]\n",
    "        for file_path in file_paths:\n",
    "            sents, labels = load_conll_file(file_path)\n",
    "            sentence_list.extend(sents)\n",
    "            sentence_label_list.extend(labels)\n",
    "        data[genre_name] = (sentence_list, sentence_label_list)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "tight-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-lunch",
   "metadata": {},
   "source": [
    "### Sanity check the full dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "visible-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------wikipedia-------\n",
      "['Csáktornyától', '12', 'km-re', 'keletre', 'fekszik', '.'] \n",
      " ['B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Az', 'Intermission', 'az', 'amerikai', 'Dio', 'heavy', 'metal', 'zenekar', 'első', 'koncertlemeze', '.'] \n",
      " ['O', 'B-MISC', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Dio', 'csalódottságában', 'nevezte', 'el', 'az', 'albumot', 'Intermission-nek', '(', 'felvonásköz', ',', 'szünet', ')', '.'] \n",
      " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------web-------\n",
      "['A', 'portát', 'kb.', '2', 'éve', 'vásároltuk', ',', 'nem', 'volt', 'rajta', 'semmi', ',', 'azóta', 'próbálkozunk', 'a', 'kertészkedéssel', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Unokatestvérem', '\"', 'talált', 'Rátok', '\"', 'és', 'mutatott', 'be', 'Nektek', '!'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Természetesen', 'szeretem', 'a', 'növényeket'] \n",
      " ['O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------news-------\n",
      "['Kikezdett', 'hozzáférés', ':', 'biztonság', ',', 'identitás', 'és', 'ellenállás', 'az', 'ázsiai', 'kibertérben', ',', 'az', 'OpenNet', 'Initiative', 'publikációja', 'decemberben', 'kerül', 'hivatalosan', 'bemutatásra', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['A', 'könyv', 'egy', 'része', '(', 'benne', 'e', 'sorok', 'szerzőjének', 'egy', 'fejezetével', ')', 'online', 'olvasható', 'és', 'letölthető', 'itt', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Események', ':', 'Érdemes', 'megnézni', 'ezt', 'az', 'internettel', 'kapcsolatos', 'eseményeket', 'gyűjtő', 'naptárat', 'az', 'Internewstől', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------fiction-------\n",
      "['Ne', 'hagyj', 'itt', '!'] \n",
      " ['O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['Shears', '?'] \n",
      " ['B-PER', 'O']\n",
      "----------------------------\n",
      "['Warden', 'a', 'nevem', '.'] \n",
      " ['B-PER', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------legal-------\n",
      "['A', 'program', 'megkönnyítette', 'a', 'görög', 'és', 'más', 'tagállamok', 'oktatási', 'és', 'képzési', 'intézményei', 'közötti', 'együttműködést', ',', 'amely', 'segíteni', 'fog', 'a', 'görög', 'oktatási', 'rendszer', 'fejlesztésében', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['A', 'nyilvántartást', '2006-ig', 'az', 'igazságügyi', 'minisztériumban', 'vezették', ',', 'majd', 'a', 'kormánybeli', 'mandátumok', 'változásával', 'átkerült', 'a', 'belügyekért', 'és', 'a', 'közigazgatásért', 'felelős', 'minisztériumhoz', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "['A', '15', 'régi', 'tagállam', 'számára', 'elsősorban', 'a', 'szennyvíz-elvezető', 'és', '-kezelő', 'rendszerek', 'karbantartása', 'és', 'felújítása', 'jelent', 'kihívást', ',', 'míg', 'az', 'új', 'tagállamoknál', 'még', 'folyamatban', 'van', 'a', 'minimálisan', 'megkövetelt', 'infrastruktúra', 'kiépítése', '.'] \n",
      " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for genre in data:\n",
    "    print(f\"-------{genre}-------\")\n",
    "    sentence_list, annotation_list = data[genre]\n",
    "    for i in range(3):\n",
    "        print(f\"{sentence_list[i]} \\n {annotation_list[i]}\")\n",
    "        print(\"----------------------------\")\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-indonesia",
   "metadata": {},
   "source": [
    "### Flatten out data & prepare for train dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "charitable-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_x = []\n",
    "flattened_y = []\n",
    "# need to create a dummy list for stratified sampling\n",
    "stratify_keys = []\n",
    "for genre in data:\n",
    "    flattened_x.extend(data[genre][0])\n",
    "    flattened_y.extend(data[genre][1])\n",
    "    stratify_keys.extend([genre for x in range(len(data[genre][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pointed-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert len(flattened_x) == len(flattened_y) == len(stratify_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "rocky-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(flattened_x, flattened_y, stratify_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "welsh-brick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Csáktornyától', '12', 'km-re', 'keletre', 'fekszik', '.'],\n",
       " ['B-LOC', 'O', 'O', 'O', 'O', 'O'],\n",
       " 'wikipedia')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "entitled-captain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65429"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "foster-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "level-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling to make sure that the distribution \n",
    "# of genres is similar in both the train and dev sets\n",
    "train, dev = train_test_split(dataset, test_size=0.25, stratify=stratify_keys, random_state=RANDOM_STATE) \n",
    "\n",
    "dev_stratify_keys = [x[2] for x in dev]\n",
    "dev, test = train_test_split(dev, test_size=0.4, stratify=dev_stratify_keys, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sought-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A',\n",
       "  'moderátorok',\n",
       "  'elsősorban',\n",
       "  'a',\n",
       "  'Felhasználók',\n",
       "  ',',\n",
       "  'illetőleg',\n",
       "  'a',\n",
       "  'Szolgáltató',\n",
       "  'érdekei',\n",
       "  'védelmében',\n",
       "  'járnak',\n",
       "  'el',\n",
       "  '.'],\n",
       " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " 'web')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d71edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Newton',\n",
       "  'hét',\n",
       "  'körcikke',\n",
       "  'azt',\n",
       "  'a',\n",
       "  'vélekedését',\n",
       "  'tükrözi',\n",
       "  ',',\n",
       "  'miszerint',\n",
       "  'hét',\n",
       "  'különálló',\n",
       "  'tiszta',\n",
       "  'színnek',\n",
       "  'kell',\n",
       "  'léteznie',\n",
       "  '.'],\n",
       " ['B-PER',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'wikipedia')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0703c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Köszönöm', ',', 'apám', '.'], ['O', 'O', 'O', 'O'], 'fiction')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b741d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blessed-classroom",
   "metadata": {},
   "source": [
    "### Dump data in a more convenient format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "controlling-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, path):\n",
    "    with open(path, 'w+') as file:\n",
    "        file.write(f'sentence\\ttoken\\ttag\\n')\n",
    "        sentence_idx = 1\n",
    "        for sentence_list, label_list, source_list in data:\n",
    "            for data_point in list(zip(sentence_list, label_list, source_list)):\n",
    "                token = data_point[0]\n",
    "                label = data_point[1]\n",
    "                file.write(f'{sentence_idx}\\t{token}\\t{label}\\n')\n",
    "            sentence_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "physical-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train, './train.tsv')\n",
    "save_data(dev, './dev.tsv')\n",
    "save_data(test, './test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "physical-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Newton</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hét</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>körcikke</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>azt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>9814</td>\n",
       "      <td>együttese</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>9814</td>\n",
       "      <td>volt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>9814</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>9814</td>\n",
       "      <td>mely</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>9814</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51868 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence      token    tag\n",
       "0             1     Newton  B-PER\n",
       "1             1        hét      O\n",
       "2             1   körcikke      O\n",
       "3             1        azt      O\n",
       "4             1          a      O\n",
       "...         ...        ...    ...\n",
       "51863      9814  együttese      O\n",
       "51864      9814       volt      O\n",
       "51865      9814          ,      O\n",
       "51866      9814       mely      O\n",
       "51867      9814          a      O\n",
       "\n",
       "[51868 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/attilanagy/Personal/bme-deep-learning-homework-ner/notebooks/dev.tsv', sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "front-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>moderátorok</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elsősorban</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Criss</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259141</th>\n",
       "      <td>49070</td>\n",
       "      <td>engedéllyel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259142</th>\n",
       "      <td>49070</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259143</th>\n",
       "      <td>49071</td>\n",
       "      <td>Mireille</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259144</th>\n",
       "      <td>49071</td>\n",
       "      <td>Hindoyan</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259145</th>\n",
       "      <td>49071</td>\n",
       "      <td>és</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence        token    tag\n",
       "0              1            A      O\n",
       "1              1  moderátorok      O\n",
       "2              1   elsősorban      O\n",
       "3              2        Criss  B-PER\n",
       "4              2            a      O\n",
       "...          ...          ...    ...\n",
       "259141     49070  engedéllyel      O\n",
       "259142     49070            .      O\n",
       "259143     49071     Mireille  B-PER\n",
       "259144     49071     Hindoyan  I-PER\n",
       "259145     49071           és      O\n",
       "\n",
       "[259146 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/attilanagy/Personal/bme-deep-learning-homework-ner/notebooks/train.tsv', sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531faf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
